from fastapi import FastAPI, UploadFile, File, Request as FastAPIRequest
from google.auth.transport.requests import Request as GoogleAuthRequest
from fastapi.middleware.cors import CORSMiddleware
from google.oauth2 import service_account
from transformers import pipeline
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification
import torch
import base64
import json
import os
import requests
import whisper
import tempfile


app = FastAPI()

#è½¬å½•éŸ³é¢‘æ–‡ä»¶ä¸ºæ–‡æœ¬
whisper_model= whisper.load_model("base")  # åŠ è½½ Whisper æ¨¡å‹ä¸€æ¬¡å³å¯
print("ğŸ§  Whisper æ¨¡å‹å·²åŠ è½½")  # âœ… è¿™å¥èƒ½å¦è¾“å‡º


@app.post("/analyze")
async def analyze_audio(file: UploadFile = File(...)):
    # å°†ä¸Šä¼ çš„éŸ³é¢‘ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name

    try:
        print("ğŸ§ å¼€å§‹è°ƒç”¨ Whisper è½¬å†™...")
        result = whisper_model.transcribe(tmp_path)
        print("ğŸ”¥ Whisper è½¬å†™ç»“æœï¼š", result)
        transcript = result["text"]

        return {
            "transcript": transcript,
            "label": "placeholder"
        }

    except Exception as e:
        print("âŒ Whisper è½¬å†™å¤±è´¥ï¼š", str(e))  # âœ… æ‰“å°é”™è¯¯
        return { "error": str(e) }



app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Google Cloud Service Account é…ç½®
SERVICE_ACCOUNT_FILE = "thermal-origin-454105-s5-c6291f413f44.json"
SCOPES = ["https://www.googleapis.com/auth/cloud-platform"]

credentials = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES
)

credentials.refresh(GoogleAuthRequest())
access_token = credentials.token

# Vertex AI endpoint è®¾ç½®
project_id = "thermal-origin-454105"  
region = "us-central1"
endpoint_id = "6002987141494210560" 
predict_url = f"https://{region}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{region}/endpoints/{endpoint_id}:predict"

@app.post("/analyze")
async def analyze_audio(file: UploadFile = File(...)):
    file_bytes = await file.read()
    base64_audio = base64.b64encode(file_bytes).decode("utf-8")

    instance = {
        "mime_type": file.content_type,
        "data": base64_audio
    }

    body = {
        "instances": [instance]
    }

    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }

    response = requests.post(predict_url, headers=headers, data=json.dumps(body))
    print("æ¨¡å‹å“åº”ï¼š", response.json())

    return response.json()


    if response.status_code != 200:
        return {"error": "è°ƒç”¨ Vertex AI å¤±è´¥", "details": response.text}

    return response.json()

# === HuggingFace Text Classification Setup ===
# åŠ è½½ fine-tuned æ¨¡å‹å’Œ tokenizerï¼ˆåªéœ€åŠ è½½ä¸€æ¬¡ï¼‰
classification_model= XLMRobertaForSequenceClassification.from_pretrained("momoali23/multilingual-hate-detector")
tokenizer = XLMRobertaTokenizer.from_pretrained("momoali23/multilingual-hate-detector")

@app.post("/analyze/fine-tuned")
async def analyze_custom_model(request: FastAPIRequest):
    data = await request.json()
    text = data.get("text", "")

    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = classification_model(**inputs)
        prediction = torch.argmax(outputs.logits, dim=1).item()
        score = torch.softmax(outputs.logits, dim=1).max().item()

    label_map = {
        0: "âœ… Normal",
        1: "ğŸš¨ Hate Speech"
    }

    return {
        "label": label_map[prediction],
    }